{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae06315-6765-401e-ac3b-4868ea7b3840",
   "metadata": {},
   "source": [
    "Data: https://zenodo.org/records/10946767\n",
    "\n",
    "The goal of the project is to create a deep learning network to predict DNA accessibility across multiple Arabidopsis experiments. The data is available on zenodo. It contains both raw read coverage files (aka BigWig files) and peak files in BED format, like the files you used in Assignment 3.  For the project, consider the problem as a regression problem, i.e. your task is to predict predict read coverage rather than the presence of peaks.\n",
    "\n",
    "The zenodo repository also includes a metadata spreadsheet that indicates the source of the biological samples (the project ID and Accession number columns) as well as the plant tissue that was used to generate the samples.\n",
    "\n",
    "In training and evaluating your models, we suggest you use chromosomes 1-4 for training and validation and chromosome 5 for testing.\n",
    "\n",
    "In your project we expect you to evaluate different architectures (e.g. purely convolutional vs transformer), explore them in terms of depth and other aspects of the design (e.g. regulation and other features such as layer normalization), and perform an analysis of the filters learned by the network.  The objective is for you to develop some intuition of what works or doesn't work in this domain.\n",
    "\n",
    "In designing your approach we recommend carefully studying the approach used in the Basenji paper that will be discussed in class.  The following paper is another useful resource:\n",
    "\n",
    "Toneyan, S., Tang, Z. & Koo, P.K. Evaluating deep learning for predicting epigenomic profiles. Nature Machine Intelligence 4, 1088â€“1100 (2022).  https://doi.org/10.1038/s42256-022-00570-9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4da94",
   "metadata": {},
   "source": [
    "Goal\n",
    "Predict DNA accessibility sites across different Arabidopsis experiments.\n",
    "\n",
    "Problem Framing:\n",
    "Given input DNA sequence, predict read coverage as a continuous, quantitative response variable.\n",
    "\n",
    "Data\n",
    "Raw Data\n",
    "Raw read coverage local filepaths (similar to those from Bassenji)\n",
    "Local filepaths of (BED) peaks (like those from Assignment 3)\n",
    "Arabidopsis genome\n",
    "\n",
    "Metadata\n",
    "Source of biological samples (project ID and Accession)\n",
    "Plant tissue identifier\n",
    "\n",
    "Training Data\n",
    "Chromosomes 1-4 will be randomly split 80/20 into train and validation data. Chromosome 5 will be held out as a test set.\n",
    "\n",
    "Data Loading\n",
    "Load in the multiple Arabidopsis experiments read coverage data, and Arabidopsis genome\n",
    "Generate testing, training, and validation set generators\n",
    "Use generator objects that will get the one hot encoded training, testing, and validation datasets so that the datasets can be randomized for each run\n",
    "\n",
    "Output: List of sequences, and coverage map of those sequences\n",
    "\n",
    "Biological Datasets\n",
    "Biologically relevant parts of the genome will be curated into datasets to explore how the models perform with known biological functions using annotations. All of these annotations will hopefully be available on ENCODE or other online resources.\n",
    "\n",
    "- Promoter dataset\n",
    "- Enhancer dataset\n",
    "- CTCF dataset \n",
    "\n",
    "\n",
    "Architecture\n",
    "We are proposing 3 different model architectures based on what we have discussed in class:\n",
    "\n",
    "- Basset model\n",
    "Small input sequence length\n",
    "3 convolutional filters\n",
    "\n",
    "- Bassenji model\n",
    "Large input sequence length (10s of kb)\n",
    "4 convolutional filters + 5 dilated convolutional filters (Arabidopsis has a ~10x smaller genome than humans)\n",
    "\n",
    "- Bassenji model with transformers\n",
    "Use positional encoding + multi-head attention layer\n",
    "\n",
    "Hyperparameters\n",
    "There are various hyperparameters that we aim to experiment with. Since we are predicting a continuous variable with a regression function, we will use a Poisson regression loss function, as done in the Bassenji model. We may look into GPyOpt (https://github.com/SheffieldML/GPyOpt) for hyperparameter optimization, but will likely just experiment with the hyperparameters manually.\n",
    "Hyper Parameters to Test (not all hyper parameters apply to all networks):\n",
    "Learning rate\n",
    "Number of layers\n",
    "Batch size\n",
    "Convolutional filter size\n",
    "Number of convolutional filters\n",
    "Input dropout rate (to inform performance on noisy data)\n",
    "Dropout rate\n",
    "Num. attention heads\n",
    "Input layer size\n",
    "Read length\n",
    "\n",
    "Prediction\n",
    "Our prediction is that the Bassenji model will be the best performing, followed by the basic Bassenji, followed by the Basset. Since we have already implemented something similar to the Basset model, this will serve as a useful benchmark.\n",
    "\n",
    "Biological Interpretation\n",
    "We aim to provide a rigorous interpretation of the biological significance of our model results, taking into account performance across different cell types, optimal read length, optimal convolutional filter size and number of filters, and other relevant aspects of model architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e196eb-0c82-45c7-ab76-e59bb4c2331c",
   "metadata": {},
   "source": [
    "Goal:\n",
    "Predict DNA accessibility sites across different Arabidopsis experiments.\n",
    "\n",
    "Problem Framing:\n",
    "Given input DNA sequence, predict read coverage as a continuous, quantitative response variable.\n",
    "\n",
    "Data:\n",
    "\n",
    "Raw Data\n",
    "\n",
    "Raw read coverage local filepaths (similar to those from Bassenji)\n",
    "Local filepaths of (BED) peaks (like those from Assignment 3)\n",
    "Arabidopsis genome\n",
    "\n",
    "Metadata\n",
    "\n",
    "Source of biological samples (project ID and Accession)\n",
    "Plant tissue identifier\n",
    "\n",
    "Training Data\n",
    "\n",
    "Chromosomes 1-4 will be randomly split 80/20 into train and validation data. Chromosome 5 will be held out as a test set.\n",
    "\n",
    "Data Loading\n",
    "\n",
    "Load in the multiple Arabidopsis experiments read coverage data, and Arabidopsis genome\n",
    "Generate testing, training, and validation set generators\n",
    "Use generator objects that will get the one hot encoded training, testing, and validation datasets so that the datasets can be randomized for each run\n",
    "\n",
    "Output: List of sequences, and coverage map of those sequences\n",
    "\n",
    "Biological Datasets\n",
    "\n",
    "Biologically relevant parts of the genome will be curated into datasets to explore how the models perform with known biological functions using annotations. All of these annotations will hopefully be available on ENCODE or other online resources.\n",
    "\n",
    "Promoter dataset\n",
    "\n",
    "Enhancer dataset\n",
    "\n",
    "CTCF dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5577c-9ebe-407a-b7bb-8da4e1d139ee",
   "metadata": {},
   "source": [
    "Human introns: 1500bp\n",
    "Arabidopsis: 150bp\n",
    "\n",
    "Basset: 600bp\n",
    "Bassenji: 130kb\n",
    "Window length: 2.5kb\n",
    "\n",
    "Human genome: 3B bases\n",
    "Arabidopsis: 100mb\n",
    "\n",
    "36 outputs (for each bigwig file)\n",
    "\n",
    "Predict single value for each 2.5kb segment\n",
    "\n",
    "Since peaks can be very high\n",
    "\n",
    "Each label is a 36 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd35fad2-8199-4eeb-9dcf-bae518081244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/tedmonyak/miniconda3/envs/gp/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/tedmonyak/miniconda3/envs/gp/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import glob\n",
    "import gzip\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "import random\n",
    "import scipy.signal\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(42);\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "#device = \"cpu\"\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd44ebc0-545a-4800-8bae-a6f219d1755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fasta file from the bigwig file\n",
    "# Generates sequences of length bin_size, sliding a window of size interval across\n",
    "# each chromosome\n",
    "# Assumes that chr_fnames already exists\n",
    "def generate_input_files_from_bw(bw_fname,\n",
    "                                 output_fasta,\n",
    "                                 output_faste,\n",
    "                                 seq_length=2500,\n",
    "                                 interval=1250):\n",
    "    bw = pyBigWig.open(bw_fname)\n",
    "    chrs = ['Chr1', 'Chr2', 'Chr3', 'Chr4', 'Chr5']\n",
    "    output_fasta = open(output_fasta, \"w\")\n",
    "    output_faste = open(output_faste, \"w\")\n",
    "    for chr_id in chrs:\n",
    "        chr_fname = chr_fnames[chr_id]\n",
    "        with gzip.open(chr_fname, \"rt\") as handle:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                chr_seq = str(record.seq)\n",
    "                chr_len = bw.chroms(chr_id)\n",
    "                bw_idx = 0\n",
    "                while bw_idx + seq_length < chr_len:\n",
    "                    coverage = \",\".join(map(str, bw.values(chr_id, bw_idx, bw_idx + seq_length)))\n",
    "                    seq = chr_seq[bw_idx:bw_idx + seq_length]\n",
    "                    seq_id =  \",\".join([chr_id, str(bw_idx), str(bw_idx+seq_length)])\n",
    "                    output_fasta.write(\">\" + seq_id + \"\\n\" + seq + \"\\n\")\n",
    "                    output_faste.write(\">\" + seq_id + \"\\n\" + coverage + \"\\n\")\n",
    "                    bw_idx += interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0cf22-cedd-4cb0-b82d-3486bd827760",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../project/chromatin_cs425'\n",
    "chr_fnames = {'Chr1': '../project/Arabidopsis_thaliana.TAIR10.dna.chromosome.1.fa.gz',\n",
    "              'Chr2': '../project/Arabidopsis_thaliana.TAIR10.dna.chromosome.2.fa.gz',\n",
    "              'Chr3': '../project/Arabidopsis_thaliana.TAIR10.dna.chromosome.3.fa.gz',\n",
    "              'Chr4': '../project/Arabidopsis_thaliana.TAIR10.dna.chromosome.4.fa.gz',\n",
    "              'Chr5': '../project/Arabidopsis_thaliana.TAIR10.dna.chromosome.5.fa.gz'}\n",
    "\n",
    "input_dirs = [os.path.join(base_dir, 'SRP034156'), os.path.join(base_dir, 'SRP300093')]\n",
    "\n",
    "bw_fname = os.path.join(base_dir, 'SRP034156', 'SRX1096548_Rep0.rpgc.bw')\n",
    "\n",
    "generate_input_files_from_bw(bw_fname,\n",
    "                             '../project/chromatin_cs425/SRP034156/fasta/SRP034156.fasta',\n",
    "                             '../project/chromatin_cs425/SRP034156/fasta/SRP034156.faste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045a65ea-3db2-43b7-a7e4-5a9640ba1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, train_size, test_size, batch_size=64):\n",
    "    train_dataset, val_dataset, test_dataset = load_data.load_data(data_dir,\n",
    "                                                                   train_val_data_to_load=train_size,\n",
    "                                                                   test_data_to_load=test_size)\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                              batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,shuffle=True)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f1269-f31f-4b77-90fd-bd9176a95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders('../project/chromatin_cs425/SRP034156/fasta',\n",
    "                                                         train_size=math.inf,\n",
    "                                                         test_size=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa152beb-09ff-4810-aa61-8e4324e1a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnaCnn(nn.Module):\n",
    "    def __init__(self, num_kernels=[20, 32, 32], kernel_size=[12,12,12],\n",
    "                 dropout=0):\n",
    "        super(DnaCnn, self).__init__()\n",
    "        self.input_channels=4\n",
    "        self.num_kernels=num_kernels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.dropout=dropout\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # first layer\n",
    "            nn.Conv1d(in_channels=self.input_channels,\n",
    "                      out_channels=num_kernels[0],\n",
    "                      kernel_size=kernel_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        # second layer\n",
    "        self.conv_block.append(nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.num_kernels[0],\n",
    "                      out_channels=num_kernels[1],\n",
    "                      kernel_size=kernel_size[1]),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(p=self.dropout),            \n",
    "        ))\n",
    "        # Add a third convolutional layer\n",
    "        self.conv_block.append(nn.Sequential(\n",
    "            # second layer\n",
    "            nn.Conv1d(in_channels=self.num_kernels[1],\n",
    "                      out_channels=num_kernels[2],\n",
    "                      kernel_size=kernel_size[2]),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(p=self.dropout),            \n",
    "        ))\n",
    "        self.regression_block = nn.Sequential(\n",
    "            nn.Linear(num_kernels[2], num_kernels[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),            \n",
    "            nn.Linear(num_kernels[2], 1)\n",
    "            #nn.Sigmoid()\n",
    "        )            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x,_ = torch.max(x, dim=2)        \n",
    "        x = self.regression_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153be5d0-b288-457b-96a8-3888ef7ee66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    # set the model to training mode - important when you have \n",
    "    # batch normalization and dropout layers\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Compute prediction and loss\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 10 == 0 :\n",
    "        print(f\"training loss: {total_loss/num_batches:>7f}\")\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validation(dataloader, model, loss_fn, epoch):\n",
    "    # set the model to evaluation mode \n",
    "    model.eval()\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients \n",
    "    # are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage \n",
    "    # for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            validation_loss += loss_fn(y_pred, y).item()\n",
    "    validation_loss /= num_batches\n",
    "    if epoch%10 == 0 :\n",
    "        print(f\"Validation Loss: {validation_loss:>8f} \\n\")\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30038341-ed6a-4314-9056-7b832bce081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    epochs = 50\n",
    "    loss_fn = nn.PoissonNLLLoss()\n",
    "    patience = 10\n",
    "    \n",
    "    train_loss = []\n",
    "    validation_loss = []\n",
    "    best_loss = math.inf\n",
    "    for t in range(epochs):\n",
    "        if t % 10 == 0 :\n",
    "            print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        loss = train_epoch(train_loader, model, loss_fn, optimizer, t)\n",
    "        train_loss.append(loss)\n",
    "        loss = validation(val_loader, model, loss_fn, t)\n",
    "        validation_loss.append(loss)\n",
    "    \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss    \n",
    "            p = patience\n",
    "        else:\n",
    "            p -= 1\n",
    "            if p == 0:\n",
    "                print(\"Early Stopping!\")\n",
    "                break    \n",
    "    print(\"Done!\")\n",
    "\n",
    "    def plot_loss():\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.plot(train_loss, label='Training')\n",
    "        plt.plot(validation_loss, label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.ylim(0)\n",
    "        plt.legend();\n",
    "\n",
    "    plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0762115-f066-42c1-acc7-287a1a9b4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DnaCnn().to(device)\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
